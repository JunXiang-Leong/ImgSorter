# -*- coding: utf-8 -*-
"""img_reconition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ByeDa-RAVO_UGvlz6xN9-VPnrTlm30Tt
"""

import tensorflow as tf
import os

gpus = tf.config.experimental.list_physical_devices('GPU')
len(gpus)

for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu,True)

"""**Filter out images**"""

import cv2
import imghdr
import sys
 
# total arguments
n = len(sys.argv)
if n != 3:
    print(f'you might have to check the inputs')

file_dir = sys.argv[1]
data_dir =  file_dir + sys.argv[2]
image_exts = ['jpeg', 'jpg', 'bmp', 'png']

for image_class in os.listdir(data_dir):
  for image in os.listdir(os.path.join(data_dir,image_class)):
    image_path = os.path.join(data_dir,image_class,image)
    try:
      img = cv2.imread(image_path)
      tip = imghdr.what(image_path)
      if tip not in image_exts:
        os.remove(image_path) #removes the image when the ext is not what we want
    except Exception as e:
      print('issue with image {}'.format(image_path))

"""Load Data"""

import numpy as np
from matplotlib import pyplot as plt

data = tf.keras.utils.image_dataset_from_directory(data_dir) #make a connection to the dataset

data_iter = data.as_numpy_iterator()
batch = data_iter.next()

"""pre-process data"""

#scaling data
data = data.map(lambda x,y :(x/255,y))

#split data
train_size = int(len(data)*0.7)
val_size = int(len(data)*0.2)+1
test_size = int(len(data)*0.1)+1

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)
len(test)

"""# **Deep learning**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten

model = Sequential()

model.add(Conv2D(16,(3,3),1, activation = 'relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())

model.add(Conv2D(32,(3,3),1, activation = 'relu'))
model.add(MaxPooling2D())

model.add(Conv2D(16,(3,3),1, activation = 'relu'))
model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(256, activation='relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.summary()

model.compile('adam',loss = tf.losses.BinaryCrossentropy(), metrics=['accuracy'])

logdir = file_dir
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)
hist = model.fit(train,epochs = 20, validation_data=val ,callbacks=[tensorboard_callback])

"""evaluate"""

from tensorflow.keras.metrics import Precision ,Recall, BinaryAccuracy

precision = Precision()
recall = Recall()
binary_acc = BinaryAccuracy()

for batch in test.as_numpy_iterator():
  X,y = batch
  y_hat = model.predict(X)
  precision.update_state(y,y_hat)
  recall.update_state(y,y_hat)
  binary_acc.update_state(y,y_hat)

print(f'Precision:{precision.result().numpy()}, Recall:{recall.result().numpy()}, Accuracy:{binary_acc.result().numpy()}')

"""saving model"""

from tensorflow.keras.models import load_model

model.save(file_dir + '\model.keras')

print('saved at', file_dir + '\model.keras')